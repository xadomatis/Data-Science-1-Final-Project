{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use hh2 dataset to train a maching learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management/Investigation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as miss\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For pre-processing data \n",
    "from sklearn import preprocessing as pp \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# For splits and CV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold # Cross validation \n",
    "from sklearn.model_selection import cross_validate # Cross validation \n",
    "from sklearn.model_selection import GridSearchCV # Cross validation + param. tuning.\n",
    "\n",
    "# Machine learning methods \n",
    "from sklearn.linear_model import LinearRegression as LM\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.tree import DecisionTreeRegressor as DTree\n",
    "from sklearn import tree # For plotting the decision tree rules\n",
    "from sklearn.ensemble import BaggingRegressor as Bag\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "\n",
    "# For evaluating our model's performance\n",
    "import sklearn.metrics as m\n",
    "\n",
    "# Pipeline to combine modeling elements\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset and remove variables where outcome is a nonstarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.read_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Data_Wrangling/hh2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70203, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh[hh.unbanked >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify all variables of interest for the testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbanked, Children under 15, Previous bank usage, income, family type, age, unemployment, citizenship, immigrant status,race, income volitility, and internet access\n",
    "hh_small = hh[[\"unbanked\",\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"]].copy()\n",
    "#removed to dummy:\n",
    "#\"hagele15\",\"hhtype\",\"hhincome\",\"prtage\"\n",
    "#needs education dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data by X and Y and prepare training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hh[\"unbanked\"]\n",
    "X = hh[[\"unbanked\",\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=.1,random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's \n",
    "scaler = pp.MinMaxScaler()\n",
    "col_names = list(train_X)\n",
    "train_X = scaler.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unbanked</th>\n",
       "      <th>bank_prev</th>\n",
       "      <th>poverty</th>\n",
       "      <th>under_25</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>citizen</th>\n",
       "      <th>native_born</th>\n",
       "      <th>White_or_AAPI</th>\n",
       "      <th>inc_vol</th>\n",
       "      <th>internet</th>\n",
       "      <th>children</th>\n",
       "      <th>single_mother</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16350</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16351</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16352 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unbanked  bank_prev  poverty  under_25  unemployed  citizen  \\\n",
       "0           0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "1           0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "2           0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "3           0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "4           0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "...         ...        ...      ...       ...         ...      ...   \n",
       "16347       0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "16348       0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "16349       0.0        0.0      1.0       0.0         0.0      0.0   \n",
       "16350       0.0        0.0      0.0       0.0         0.0      0.0   \n",
       "16351       0.0        0.0      0.0       0.0         0.0      0.5   \n",
       "\n",
       "       native_born  White_or_AAPI  inc_vol  internet  children  single_mother  \n",
       "0              0.0            1.0      1.0       1.0       0.0            0.0  \n",
       "1              0.0            0.0      1.0       0.0       0.0            0.0  \n",
       "2              0.0            0.0      0.0       1.0       0.0            0.0  \n",
       "3              0.0            1.0      0.0       1.0       1.0            0.0  \n",
       "4              0.0            1.0      1.0       1.0       1.0            0.0  \n",
       "...            ...            ...      ...       ...       ...            ...  \n",
       "16347          0.0            1.0      0.0       1.0       1.0            0.0  \n",
       "16348          0.0            0.0      0.0       1.0       0.0            0.0  \n",
       "16349          0.0            0.0      1.0       1.0       0.0            1.0  \n",
       "16350          0.0            0.0      1.0       1.0       1.0            0.0  \n",
       "16351          0.5            1.0      0.0       1.0       1.0            0.0  \n",
       "\n",
       "[16352 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back into data frame\n",
    "train_X = pd.DataFrame(train_X,columns=col_names)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Set the folds index to ensure comparable samples\n",
    "fold_generator = KFold(n_splits=5, shuffle=True,random_state=111)\n",
    "\n",
    "# (2) Next specify the preprocessing steps\n",
    "preprocess = ColumnTransformer(transformers=[('num', pp.MinMaxScaler(), [\"unbanked\",\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"])])\n",
    "\n",
    "\n",
    "# (3) Next Let's create our model pipe (note for the model we leave none as a placeholder)\n",
    "pipe = Pipeline(steps=[('pre_process', preprocess),\n",
    "                       ('model',None)])\n",
    "\n",
    "\n",
    "# (4) Specify the models and their repsective tuning parameters. \n",
    "# Note the naming convention here to reference the model key\n",
    "search_space = [\n",
    "    # Linear Model\n",
    "    {'model' : [LM()]},\n",
    "    \n",
    "    # KNN with K tuning param\n",
    "    {'model' : [KNN()],\n",
    "     'model__n_neighbors':[10,15,20,25,30]},\n",
    "    \n",
    "    # Decision Tree with the Max Depth Param\n",
    "    {'model': [DTree()],\n",
    "     'model__max_depth':[1,2,3,5]},\n",
    "    \n",
    "    # The Bagging decision tree model \n",
    "    {'model': [Bag()]},\n",
    "    \n",
    "    # Random forest with the N Estimators tuning param\n",
    "    {'model' : [RF()],\n",
    "     'model__max_depth':[1,2,3],\n",
    "     'model__n_estimators':[500,1000,1250]},\n",
    "]\n",
    "\n",
    "\n",
    "# (5) Put it all together in the grid search\n",
    "search = GridSearchCV(pipe, search_space, \n",
    "                      cv = fold_generator,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      n_jobs=4)\n",
    "\n",
    "# (6) Fit the model to the training data\n",
    "search.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = search.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.mean_squared_error(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.r2_score(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.accuracy_score(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(pd.DataFrame(dict(pred=pred_y,truth=test_y)),\n",
    "          aes(x='pred',y=\"truth\")) +\n",
    "    geom_jitter(color=\"darkgreen\", size=.1, width = 0.2, height = 0.2) +\n",
    "    geom_abline(color=\"gold\",size=1) +\n",
    "    theme_bw() \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Decision Tree Seperately since it's the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.confusion_matrix(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = hh_small.corr()\n",
    "correlation_mat = correlation_mat.round(decimals = 2)\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
