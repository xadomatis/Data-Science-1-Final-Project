{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use hh2 dataset to train a maching learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management/Investigation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as miss\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For pre-processing data \n",
    "from sklearn import preprocessing as pp \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# For splits and CV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold # Cross validation \n",
    "from sklearn.model_selection import cross_validate # Cross validation \n",
    "from sklearn.model_selection import GridSearchCV # Cross validation + param. tuning.\n",
    "\n",
    "# Machine learning methods \n",
    "from sklearn.linear_model import LinearRegression as LM\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNN\n",
    "from sklearn.tree import DecisionTreeRegressor as DTree\n",
    "from sklearn import tree # For plotting the decision tree rules\n",
    "from sklearn.ensemble import BaggingRegressor as Bag\n",
    "from sklearn.ensemble import RandomForestRegressor as RF\n",
    "\n",
    "# For evaluating our model's performance\n",
    "import sklearn.metrics as m\n",
    "\n",
    "# Pipeline to combine modeling elements\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Management/Investigation\n",
    "import pandas as pd\n",
    "from pandas.api.types import CategoricalDtype # Ordering categories\n",
    "import numpy as np\n",
    "import missingno as miss\n",
    "\n",
    "# Plotting libraries\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For pre-processing data \n",
    "from sklearn import preprocessing as pp \n",
    "from sklearn.compose import ColumnTransformer \n",
    "\n",
    "# For splits and CV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold # Cross validation \n",
    "from sklearn.model_selection import cross_validate # Cross validation \n",
    "from sklearn.model_selection import GridSearchCV # Cross validation + param. tuning.\n",
    "\n",
    "# Machine learning methods \n",
    "from sklearn.naive_bayes import GaussianNB as NB\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DT\n",
    "from sklearn.tree import DecisionTreeRegressor as DT_reg\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn import tree # For plotting the decision tree rules\n",
    "\n",
    "# For evaluating our model's performance\n",
    "import sklearn.metrics as m\n",
    "\n",
    "# Pipeline to combine modeling elements\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For model interpretation\n",
    "from sklearn.inspection import (\n",
    "    permutation_importance,\n",
    "    partial_dependence, \n",
    "    PartialDependenceDisplay, \n",
    "    plot_partial_dependence\n",
    ")\n",
    "\n",
    "# Misc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Dataset and remove variables where outcome is a nonstarter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.read_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Data_Wrangling/hh2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70203, 33)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh[hh.unbanked >= 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = hh.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify all variables of interest for the testing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unbanked, Children under 15, Previous bank usage, income, family type, age, unemployment, citizenship, immigrant status,race, income volitility, and internet access\n",
    "hh_small = hh[[\"unbanked\",\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"]].copy()\n",
    "#removed to dummy:\n",
    "#\"hagele15\",\"hhtype\",\"hhincome\",\"prtage\"\n",
    "#needs education dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data by X and Y and prepare training sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hh[\"unbanked\"]\n",
    "X = hh[[\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(X,y,test_size=.1,random_state=1999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's \n",
    "scaler = pp.MinMaxScaler()\n",
    "col_names = list(train_X)\n",
    "train_X = scaler.fit_transform(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bank_prev</th>\n",
       "      <th>poverty</th>\n",
       "      <th>under_25</th>\n",
       "      <th>unemployed</th>\n",
       "      <th>citizen</th>\n",
       "      <th>native_born</th>\n",
       "      <th>White_or_AAPI</th>\n",
       "      <th>inc_vol</th>\n",
       "      <th>internet</th>\n",
       "      <th>children</th>\n",
       "      <th>single_mother</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16347</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16348</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16349</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16350</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16351</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16352 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       bank_prev  poverty  under_25  unemployed  citizen  native_born  \\\n",
       "0            0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "1            0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "2            0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "3            0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "4            0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "...          ...      ...       ...         ...      ...          ...   \n",
       "16347        0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "16348        0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "16349        0.0      1.0       0.0         0.0      0.0          0.0   \n",
       "16350        0.0      0.0       0.0         0.0      0.0          0.0   \n",
       "16351        0.0      0.0       0.0         0.0      0.5          0.5   \n",
       "\n",
       "       White_or_AAPI  inc_vol  internet  children  single_mother  \n",
       "0                1.0      1.0       1.0       0.0            0.0  \n",
       "1                0.0      1.0       0.0       0.0            0.0  \n",
       "2                0.0      0.0       1.0       0.0            0.0  \n",
       "3                1.0      0.0       1.0       1.0            0.0  \n",
       "4                1.0      1.0       1.0       1.0            0.0  \n",
       "...              ...      ...       ...       ...            ...  \n",
       "16347            1.0      0.0       1.0       1.0            0.0  \n",
       "16348            0.0      0.0       1.0       0.0            0.0  \n",
       "16349            0.0      1.0       1.0       0.0            1.0  \n",
       "16350            0.0      1.0       1.0       1.0            0.0  \n",
       "16351            1.0      0.0       1.0       1.0            0.0  \n",
       "\n",
       "[16352 rows x 11 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert back into data frame\n",
    "train_X = pd.DataFrame(train_X,columns=col_names)\n",
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=KFold(n_splits=5, random_state=111, shuffle=True),\n",
       "             estimator=Pipeline(steps=[('pre_process',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         MinMaxScaler(),\n",
       "                                                                         ['bank_prev',\n",
       "                                                                          'poverty',\n",
       "                                                                          'under_25',\n",
       "                                                                          'unemployed',\n",
       "                                                                          'citizen',\n",
       "                                                                          'native_born',\n",
       "                                                                          'White_or_AAPI',\n",
       "                                                                          'inc_vol',\n",
       "                                                                          'internet',\n",
       "                                                                          'children',\n",
       "                                                                          'single_mother'])])),\n",
       "                                       ('model', None)]),\n",
       "             n_jobs=4,\n",
       "             param_grid=[{'model': [LinearRegression()]},\n",
       "                         {'model': [KNeighborsClassifier()],\n",
       "                          'model__n_neighbors': [10, 15, 20, 25, 30]},\n",
       "                         {'model': [DecisionTreeRegressor(max_depth=5)],\n",
       "                          'model__max_depth': [1, 2, 3, 5]},\n",
       "                         {'model': [BaggingRegressor()]},\n",
       "                         {'model': [RandomForestClassifier()],\n",
       "                          'model__max_depth': [1, 2, 3],\n",
       "                          'model__n_estimators': [500, 1000, 1250]}],\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (1) Set the folds index to ensure comparable samples\n",
    "fold_generator = KFold(n_splits=5, shuffle=True,random_state=111)\n",
    "\n",
    "# (2) Next specify the preprocessing steps\n",
    "preprocess = ColumnTransformer(transformers=[('num', pp.MinMaxScaler(), [\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"])])\n",
    "\n",
    "\n",
    "# (3) Next Let's create our model pipe (note for the model we leave none as a placeholder)\n",
    "pipe = Pipeline(steps=[('pre_process', preprocess),\n",
    "                       ('model',None)])\n",
    "\n",
    "\n",
    "# (4) Specify the models and their repsective tuning parameters. \n",
    "# Note the naming convention here to reference the model key\n",
    "search_space = [\n",
    "    # Linear Model\n",
    "    {'model' : [LM()]},\n",
    "    \n",
    "    # KNN with K tuning param\n",
    "    {'model' : [KNN()],\n",
    "     'model__n_neighbors':[10,15,20,25,30]},\n",
    "    \n",
    "    # Decision Tree with the Max Depth Param\n",
    "    {'model': [DTree()],\n",
    "     'model__max_depth':[1,2,3,5]},\n",
    "    \n",
    "    # The Bagging decision tree model \n",
    "    {'model': [Bag()]},\n",
    "    \n",
    "    # Random forest with the N Estimators tuning param\n",
    "    {'model' : [RF()],\n",
    "     'model__max_depth':[1,2,3],\n",
    "     'model__n_estimators':[500,1000,1250]},\n",
    "]\n",
    "\n",
    "\n",
    "# (5) Put it all together in the grid search\n",
    "search = GridSearchCV(pipe, search_space, \n",
    "                      cv = fold_generator,\n",
    "                      scoring='neg_mean_squared_error',\n",
    "                      n_jobs=4)\n",
    "\n",
    "# (6) Fit the model to the training data\n",
    "search.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022055422101177603"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': DecisionTreeRegressor(max_depth=5), 'model__max_depth': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best model is a random forest so we need to establish it as a variable\n",
    "dtree = search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = search.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02512841645243429"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.mean_squared_error(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5122282751547441"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.r2_score(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-9721cca40ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[0m\u001b[1;32m     91\u001b[0m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "m.accuracy_score(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permute features to determine importances\n",
    "vi = permutation_importance(dtree,train_X,train_y,n_repeats=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(\n",
    "    ggplot(pd.DataFrame(dict(pred=pred_y,truth=test_y)),\n",
    "          aes(x='pred',y=\"truth\")) +\n",
    "    geom_jitter(color=\"darkgreen\", size=.1, width = 0.2, height = 0.2) +\n",
    "    geom_abline(color=\"gold\",size=1) +\n",
    "    theme_bw() \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Decision Tree Seperately since it's the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.confusion_matrix(test_y,pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_mat = hh_small.corr()\n",
    "correlation_mat = correlation_mat.round(decimals = 2)\n",
    "sns.heatmap(correlation_mat, annot = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/test_bi\", test_y, delimiter=\",\")\n",
    "np.savetxt(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/pred_bi\", pred_y, delimiter=\",\")\n",
    "np.savetxt(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/corr\", correlation_mat, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#permute features to determine importances\n",
    "vi = permutation_importance(dtree,train_X,train_y,n_repeats=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organize as a data frame \n",
    "vi_dat = pd.DataFrame(dict(variable=train_X.columns,\n",
    "                           vi = vi['importances_mean'],\n",
    "                           std = vi['importances_std']))\n",
    "\n",
    "# Generate intervals\n",
    "vi_dat['low'] = vi_dat['vi'] - 2*vi_dat['std']\n",
    "vi_dat['high'] = vi_dat['vi'] + 2*vi_dat['std']\n",
    "\n",
    "# But in order from most to least important\n",
    "vi_dat = vi_dat.sort_values(by=\"vi\",ascending=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "vi_dat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
