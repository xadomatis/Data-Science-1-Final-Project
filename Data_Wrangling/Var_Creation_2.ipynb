{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this document I'll create and modify variables necessary for my machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh = pd.read_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Data_Wrangling/hh_2019.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in previous work with the data, I've noticed that hrhhid is almost unique but approximatley 5000 households share the same ID (duplexes or roommates I've been told)\n",
    "#the two ID numbers have to be combines to have as an index\n",
    "unique_id = hh['hrhhid'] + hh['hrhhid2']\n",
    "hh.insert(0,\"id\",unique_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop irrelevant ID columns\n",
    "hh = hh.drop(hh.columns[1:4], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replace all of the unknowns (usually as 99) with nul\n",
    "hh = hh.replace(99,'')\n",
    "hh = hh.replace(\".\",'')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import other datasets\n",
    "pop = pd.read_excel(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Other_Data/State_Population.xlsx\")\n",
    "ur_banks = pd.read_excel(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Other_Data/State_UR_and_Banks.xlsx\")\n",
    "st_conv = pd.read_excel(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Other_Data/State_ST_FIPS.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>pop_2020</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>5024279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>733391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>American Samoa[10]</td>\n",
       "      <td>49710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>7151502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>3011524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                State  pop_2020\n",
       "0             Alabama   5024279\n",
       "1              Alaska    733391\n",
       "2  American Samoa[10]     49710\n",
       "3             Arizona   7151502\n",
       "4            Arkansas   3011524"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fix a weird spacing issue on pop\n",
    "pop['State'] = pop['State'].str[1:]\n",
    "pop.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge datasets on FIPS codes\n",
    "fips_ur_banks = pd.merge(ur_banks,st_conv, on='ST')\n",
    "fips_pop = pd.merge(pop,st_conv, on='State')\n",
    "st_lvl = pd.merge(fips_pop,fips_ur_banks,on='FIPS',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIPS</th>\n",
       "      <th>ST_bnk_density</th>\n",
       "      <th>ST_UR_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>5.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>4.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   FIPS  ST_bnk_density  ST_UR_19\n",
       "0     1        0.000022       3.0\n",
       "1     2        0.000007       5.4\n",
       "2     4        0.000002       4.9\n",
       "3     5        0.000029       3.5\n",
       "4     6        0.000004       4.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create a bank density and pull in the unemployment variable\n",
    "st_lvl[\"ST_bnk_density\"] = st_lvl[\"ST_NUM_BANKS\"] / st_lvl[\"pop_2020\"]\n",
    "FIPS_dict = st_lvl[[\"FIPS\",\"ST_bnk_density\",\"ST_UR_19\"]]\n",
    "FIPS_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['FIPS'] = hh['gestfips']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gestfips</th>\n",
       "      <th>msa13</th>\n",
       "      <th>gtcbsast</th>\n",
       "      <th>hagele15</th>\n",
       "      <th>hbnkprev</th>\n",
       "      <th>hhincome</th>\n",
       "      <th>hhtenure</th>\n",
       "      <th>hhtype</th>\n",
       "      <th>hryear4</th>\n",
       "      <th>...</th>\n",
       "      <th>hincvolv2</th>\n",
       "      <th>hintaccv2</th>\n",
       "      <th>hbnkint</th>\n",
       "      <th>hunbnkrmv4</th>\n",
       "      <th>hhfamtyp</th>\n",
       "      <th>hsupresp</th>\n",
       "      <th>hsupwgtk</th>\n",
       "      <th>FIPS</th>\n",
       "      <th>ST_bnk_density</th>\n",
       "      <th>ST_UR_19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>70198</th>\n",
       "      <td>521069004358376</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70199</th>\n",
       "      <td>710004565263948</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70200</th>\n",
       "      <td>614830557651116</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70201</th>\n",
       "      <td>561163008560585</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70202</th>\n",
       "      <td>654240932191116</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2019</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id  gestfips  msa13  gtcbsast  hagele15 hbnkprev hhincome  \\\n",
       "70198  521069004358376        56      0         3         0                 2   \n",
       "70199  710004565263948        56      0         3         0                     \n",
       "70200  614830557651116        56      0         3         0                     \n",
       "70201  561163008560585        56      0         3         0                     \n",
       "70202  654240932191116        56      0         3         0                     \n",
       "\n",
       "       hhtenure  hhtype  hryear4  ... hincvolv2  hintaccv2 hbnkint  \\\n",
       "70198         1       1     2019  ...                   -1      -1   \n",
       "70199         1       6     2019  ...                   -1      -1   \n",
       "70200         2       6     2019  ...                   -1      -1   \n",
       "70201         2       6     2019  ...                   -1      -1   \n",
       "70202         2       6     2019  ...                   -1      -1   \n",
       "\n",
       "       hunbnkrmv4  hhfamtyp hsupresp  hsupwgtk FIPS  ST_bnk_density  ST_UR_19  \n",
       "70198          -1         1        0       0.0   56        0.000052       3.7  \n",
       "70199          -1                  0       0.0   56        0.000052       3.7  \n",
       "70200          -1                  0       0.0   56        0.000052       3.7  \n",
       "70201          -1                  0       0.0   56        0.000052       3.7  \n",
       "70202          -1                  0       0.0   56        0.000052       3.7  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#add the new demographics to the dataset\n",
    "hh = pd.merge(hh,FIPS_dict,on=['FIPS'],how='left')\n",
    "hh.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create dummy variables for certain variables with 3-5 outcomes, to simplify regressions. These are categorical variables that really don't need to be categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make an urban variable that is 1 if in or around a metro area and zero if not\n",
    "hh['urban'] = hh['gtcbsast']\n",
    "hh['urban'] = hh['urban'].replace(2,1)\n",
    "hh['urban'] = hh['urban'].replace(3,0)\n",
    "hh['urban'] = hh['urban'].replace(4,'')\n",
    "hh = hh.drop(['gtcbsast'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['bank_prev'] = hh['hbnkprev']\n",
    "hh['bank_prev'] = hh['bank_prev'].replace(2,0)\n",
    "hh['bank_prev'] = hh['bank_prev'].replace(-1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['unbanked'] = hh['hunbnk']\n",
    "hh['unbanked'] = hh['unbanked'].replace(2,0)\n",
    "hh = hh.drop(['hunbnk'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Ed dummies\n",
    "hh['no_diploma'] = hh['peducgrp']\n",
    "hh['no_diploma'] = hh['no_diploma'].replace(2,0)\n",
    "hh['no_diploma'] = hh['no_diploma'].replace(3,0)\n",
    "hh['no_diploma'] = hh['no_diploma'].replace(4,0)\n",
    "hh['no_college'] = hh['peducgrp']\n",
    "hh['no_college'] = hh['no_college'].replace(2,1)\n",
    "hh['no_college'] = hh['no_college'].replace(3,0)\n",
    "hh['no_college'] = hh['no_college'].replace(4,0)\n",
    "hh['degree'] = hh['peducgrp']\n",
    "hh['degree'] = hh['degree'].replace(1,0)\n",
    "hh['degree'] = hh['degree'].replace(3,1)\n",
    "hh['degree'] = hh['degree'].replace(2,0)\n",
    "hh['degree'] = hh['degree'].replace(4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh['poverty'] = hh['hhincome']\n",
    "hh['poverty'] = hh['poverty'].replace(2,0)\n",
    "hh['poverty'] = hh['poverty'].replace(3,0)\n",
    "hh['poverty'] = hh['poverty'].replace(4,0)\n",
    "hh['poverty'] = hh['poverty'].replace(5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a binary that is 1 if repondent is a citizen and 0 if respondent is not\n",
    "hh['citizen'] = hh['pnativ']\n",
    "hh['citizen'] = hh['citizen'].replace(2,1)\n",
    "hh['citizen'] = hh['citizen'].replace(3,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#binary where 1 is a native born and 0 is foreign born\n",
    "hh['native_born'] = hh['pnativ']\n",
    "hh['native_born'] = hh['native_born'].replace(2,0)\n",
    "hh['native_born'] = hh['native_born'].replace(3,0)\n",
    "hh = hh.drop(['pnativ'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hagele15\n",
    "#fix the homeownership variable to be a dummy\n",
    "#1 has children 0 does not\n",
    "hh['children'] = (hh['hagele15'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hagele15\n",
    "#fix the homeownership variable to be a dummy\n",
    "#1 is under 25 0 is older\n",
    "hh['under_25'] = (hh['prtage'] < 26).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hhtype\n",
    "#fix family type to dummy\n",
    "#1 is single mother 0 is not\n",
    "hh['single_mother'] = hh['hhtype']\n",
    "hh['single_mother'] = hh['single_mother'].replace(1,0)\n",
    "hh['single_mother'] = hh['single_mother'].replace(3,0)\n",
    "hh['single_mother'] = hh['single_mother'].replace(4,0)\n",
    "hh['single_mother'] = hh['single_mother'].replace(5,0)\n",
    "hh['single_mother'] = hh['single_mother'].replace(6,0)\n",
    "hh['single_mother'] = hh['single_mother'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the homeownership variable to be a dummy\n",
    "#1 is homeowner 0 is not\n",
    "hh['homeowner'] = hh['hhtenure']\n",
    "hh['homeowner'] = hh['homeowner'].replace(2,0)\n",
    "hh = hh.drop(['hhtenure'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the unbanked variable to be a dummy\n",
    "#1 is unemployed 0 is not\n",
    "hh['unemployed'] = hh['pempstat']\n",
    "hh['unemployed'] = hh['unemployed'].replace(1,0)\n",
    "hh['unemployed'] = hh['unemployed'].replace(3,0)\n",
    "hh['unemployed'] = hh['unemployed'].replace(2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix volatility dummy\n",
    "#1 is income volitility 0 is stablle\n",
    "hh['inc_vol'] = hh['hincvolv2']\n",
    "hh['inc_vol'] = hh['inc_vol'].replace(1,0)\n",
    "hh['inc_vol'] = hh['inc_vol'].replace(2,1)\n",
    "hh = hh.drop(['hincvolv2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the internet acces variable variable to be a dummy\n",
    "#1 has internet access 0 does not\n",
    "hh['internet'] = hh['hintaccv2']\n",
    "hh['internet'] = hh['internet'].replace(2,0)\n",
    "hh = hh.drop(['hintaccv2'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix the disability variable to be a dummy\n",
    "#1 is udisabled 0 is not\n",
    "hh['disability'] = hh['pdisabl_age25to64']\n",
    "hh['disability'] = hh['disability'].replace(2,0)\n",
    "hh = hh.drop(['pdisabl_age25to64'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert continuous variables to legible names\n",
    "hh['income'] = hh['hhincome']\n",
    "hh['education'] = hh['peducgrp']\n",
    "hh['age'] = hh['prtage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splid data by under 5 and over 5\n",
    "#1 for White or Asian American or Pacific Islander, 0 for Other People of Color\n",
    "hh['White_or_AAPI'] = hh['praceeth3']\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(1,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(2,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(3,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(4,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(5,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(6,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(7,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_small = hh[[\"unbanked\",\"urban\",\"homeowner\",\"disability\",\"degree\",\"no_college\",\"no_diploma\",\"FIPS\",\"ST_bnk_density\",\"ST_UR_19\",\"income\",\"age\",\"education\",\"bank_prev\",\"poverty\",\"under_25\",\"unemployed\",\"citizen\",\"native_born\",\"White_or_AAPI\",\"inc_vol\",\"internet\",\"children\",\"single_mother\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_small.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh_small.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Data_Wrangling/hh4.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I create dummy variables based on clusered outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify clusters in age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agegrp = pd.crosstab(hh.unbanked,hh.prtage)\n",
    "agegrp = agegrp.transpose()\n",
    "agegrp.reset_index(inplace=True)\n",
    "agegrp.columns = ['age','num_banked','num_unbanked','num_NA']\n",
    "agegrp['pct_unb'] = 100*agegrp['num_unbanked']/(agegrp['num_unbanked']+ agegrp['num_banked'])\n",
    "agegrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import plotnine as p9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data=agegrp, mapping=p9.aes(x='age', y='pct_unb'))+\n",
    " geom_point(size=3,alpha=.5,show_legend=True) +\n",
    " labs(x='Age', y='Percent Unbanked',color=\"\",title=\"Percent Unbanked by Age\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Originally, I planned to bin age or at least create a few binary variables; now, however, it seems that age flows fairly linearly and doesn't need any binsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visually identify any unbanked clusters in race\n",
    "racegrp = pd.crosstab(hh.unbanked,hh.praceeth3)\n",
    "racegrp = racegrp.transpose()\n",
    "racegrp.reset_index(inplace=True)\n",
    "racegrp.columns = ['race','num_banked','num_unbanked','num_NA']\n",
    "racegrp['pct_unb'] = 100*racegrp['num_unbanked']/(racegrp['num_unbanked']+ racegrp['num_banked'])\n",
    "racegrp['race_name'] = ['Black', 'Hispanic', 'Asian', 'Native', 'Pacific', 'White', 'Biracial']\n",
    "racegrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(ggplot(racegrp)       \n",
    " + aes(x='race_name', y='pct_unb')    \n",
    " + geom_bar(stat=\"identity\") # defining the type of plot to use\n",
    " + labs(title='Percent Unbanked by Race', x='Race', y='Percent Unbanked') \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Race, I think we can justify Bins, especially since it is purely categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splid data by under 5 and over 5\n",
    "#1 for White or Asian American or Pacific Islander, 0 for Other People of Color\n",
    "hh['White_or_AAPI'] = hh['praceeth3']\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(1,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(2,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(3,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(4,0)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(5,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(6,1)\n",
    "hh['White_or_AAPI'] = hh['White_or_AAPI'].replace(7,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Main Dataset for Pre-Processing Review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Data_Wrangling/hh2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Datasets for Slide Graphing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Export Already Initialized Data Groups\n",
    "racegrp.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/race_unbanked\")\n",
    "agegrp.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/age_unbanked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset for education\n",
    "edgrp = pd.crosstab(hh.unbanked,hh.peducgrp)\n",
    "edgrp = edgrp.transpose()\n",
    "edgrp.reset_index(inplace=True)\n",
    "edgrp.columns = ['ed_level','num_banked','num_unbanked','num_NA']\n",
    "edgrp['pct_unb'] = 100*edgrp['num_unbanked']/(edgrp['num_unbanked']+ edgrp['num_banked'])\n",
    "edgrp['ed_name'] = ['No Diploma','Diploma','No Degree','Degree']\n",
    "edgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset for family type\n",
    "ftgrp = pd.crosstab(hh.unbanked,hh.hhtype)\n",
    "ftgrp = ftgrp.transpose()\n",
    "ftgrp.reset_index(inplace=True)\n",
    "ftgrp.columns = ['family_type','num_banked','num_unbanked','num_NA']\n",
    "ftgrp['pct_unb'] = 100*ftgrp['num_unbanked']/(ftgrp['num_unbanked']+ ftgrp['num_banked'])\n",
    "ftgrp['ft_name'] = ['Couple', 'F-Led Fam', 'M-Led Fam', 'F Ind', 'M Ind','Other']\n",
    "ftgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset for income\n",
    "incgrp = pd.crosstab(hh.unbanked,hh.hhincome)\n",
    "incgrp = incgrp.transpose()\n",
    "incgrp.reset_index(inplace=True)\n",
    "incgrp.columns = ['income','num_banked','num_unbanked','num_NA']\n",
    "incgrp['pct_unb'] = 100*incgrp['num_unbanked']/(incgrp['num_unbanked']+ incgrp['num_banked'])\n",
    "incgrp['inc_name'] = ['<15k', '15k-30k', '30k-50k', '50k-75k', '75k+','no response']\n",
    "incgrp = incgrp.drop(5)\n",
    "incgrp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export other variables\n",
    "#Export Already Initialized Data Groups\n",
    "edgrp.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/ed_unbanked\")\n",
    "ftgrp.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/ft_unbanked\")\n",
    "incgrp.to_csv(\"/Users/xavier/Desktop/DSPP/DS/Data-Science-1-Final-Project/Slides/graph_data/income_unbanked\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
